{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Example\n",
    "\n",
    "In this example, we'll use sklearn's `GridSearchCV` class to find\n",
    "optimal hyperparameters of the `RandomForestClassifier` estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library with the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load numpy\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# train_test_split: for splitting data into training and test datasets\n",
    "# GridSearchCV: for hyperparameter tuning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Evaluate our results\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "Since the `load_iris()` function returns the data as numpy matrices already, we\n",
    "won't be dealing with any Pandas data frames just yet. If we were starting with\n",
    "Pandas, we'd need to convert to numpy matrices first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object called iris with the iris data\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the predictor attributes\n",
    "X = iris.data\n",
    "\n",
    "# Extract the target attribute\n",
    "y = iris.target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (100, 4)\n",
      "y_train: (100, 1)\n",
      "X_test: (50, 4)\n",
      "y_test: (50, 1)\n"
     ]
    }
   ],
   "source": [
    "# Display shape of the new datasets\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct hyperparameter tuning\n",
    "\n",
    "We must be careful NOT TO USE the test dataset during this process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the parameters to be tuned\n",
    "tuned_parameters = {\n",
    "    'n_estimators': range(20,101,5),\n",
    "    'max_depth': range(20,61,5),\n",
    "    'n_estimators': range(10,41,5),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a GridSearchCV object\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    tuned_parameters,\n",
    "    cv=5, # 5-fold cross-validation\n",
    "    scoring='precision_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 103 ms, total: 19.6 s\n",
      "Wall time: 19.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': range(10, 41, 5), 'max_depth': range(20, 61, 5), 'max_features': ['sqrt', 'log2', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision_weighted', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Conduct the tuning. This may take a little while.\n",
    "clf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We trained 189 models.\n"
     ]
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "print(\"We trained {} models.\".format(len(cv_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model gave score of 0.967\n",
      "Parameters: {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best model gave score of {:.3f}\".format(clf.best_score_))\n",
    "print(\"Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the details of that job:\n",
      "mean_fit_time                                                 0.0134144\n",
      "std_fit_time                                                 0.00180222\n",
      "mean_score_time                                              0.00189981\n",
      "std_score_time                                              0.000187811\n",
      "param_max_depth                                                      20\n",
      "param_max_features                                                 log2\n",
      "param_n_estimators                                                   20\n",
      "params                {'max_depth': 20, 'max_features': 'log2', 'n_e...\n",
      "split0_test_score                                              0.925926\n",
      "split1_test_score                                                     1\n",
      "split2_test_score                                                     1\n",
      "split3_test_score                                               0.95625\n",
      "split4_test_score                                              0.953947\n",
      "mean_test_score                                                0.966944\n",
      "std_test_score                                                0.0290752\n",
      "rank_test_score                                                       1\n",
      "split0_train_score                                                    1\n",
      "split1_train_score                                                    1\n",
      "split2_train_score                                                    1\n",
      "split3_train_score                                                    1\n",
      "split4_train_score                                                    1\n",
      "mean_train_score                                                      1\n",
      "std_train_score                                                       0\n",
      "Name: 9, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the details of that job:\")\n",
    "print(cv_results.loc[clf.best_index_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate how well this model will generalize to unseen data\n",
    "We'll do this by making predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now estimate generalization error by\n",
    "# using our optimal model to make predictions on the test set.\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.95      0.95      0.95        19\n",
      "           2       0.93      0.93      0.93        15\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        50\n",
      "   macro avg       0.96      0.96      0.96        50\n",
      "weighted avg       0.96      0.96      0.96        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report (rows are the target classes 0, 1, 2)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960\n"
     ]
    }
   ],
   "source": [
    "# How well will this model generalize to unseen data (in terms of overall accuracy)?\n",
    "print('{:.3f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
